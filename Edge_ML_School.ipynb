{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aS9wFAA6hzz2"
   },
   "source": [
    "# 1. QONNX - How to work with models\n",
    "\n",
    "We first start to create and manipulate an ONNX model and learn to use some QONNX functions to work with it.\n",
    "\n",
    "NOTE: most of this is based on https://github.com/onnx/tutorials and https://github.com/fastmachinelearning/qonnx/tree/main/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QyZeAR2sh2Ze",
    "outputId": "ffe28231-a267-4c74-9e67-0adf40ee5026"
   },
   "outputs": [],
   "source": [
    "# lets first install qonnx and onnx\n",
    "%pip install qonnx\n",
    "%pip install onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Yjvjoich6tA"
   },
   "source": [
    "### 1.1. How to create a simple ONNX model\n",
    "\n",
    "To explain how to create an ONNX model a simple example with mathematical operations is used. All nodes are from the [standard operations library of ONNX](https://github.com/onnx/onnx/blob/master/docs/Operators.md).\n",
    "\n",
    "First ONNX is imported, then the helper function can be used to make a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEdP7fjPh4dI"
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "from qonnx.util.basic import qonnx_make_model\n",
    "\n",
    "Add1_node = onnx.helper.make_node(\n",
    "    'Add',\n",
    "    inputs=['in1', 'in2'],\n",
    "    outputs=['sum1'],\n",
    "    name='Add1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXBpS0jFiGJX"
   },
   "source": [
    "The first attribute of the node is the operation type. In this case it is `'Add'`, so it is an adder node. Then the input names are passed to the node and at the end a name is assigned to the output.\n",
    "    \n",
    "For this example we want two other adder nodes, one abs node and the output shall be rounded so one round node is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5vU8ZL3iBKZ"
   },
   "outputs": [],
   "source": [
    "Add2_node = onnx.helper.make_node(\n",
    "    'Add',\n",
    "    inputs=['sum1', 'in3'],\n",
    "    outputs=['sum2'],\n",
    "    name='Add2',\n",
    ")\n",
    "\n",
    "Abs_node = onnx.helper.make_node(\n",
    "    'Abs',\n",
    "    inputs=['sum2'],\n",
    "    outputs=['abs1'],\n",
    "    name='Abs'\n",
    ")\n",
    "\n",
    "Add3_node = onnx.helper.make_node(\n",
    "    'Add',\n",
    "    inputs=['abs1', 'abs1'],\n",
    "    outputs=['sum3'],\n",
    "    name='Add3',\n",
    ")\n",
    "\n",
    "Round_node = onnx.helper.make_node(\n",
    "    'Round',\n",
    "    inputs=['sum3'],\n",
    "    outputs=['out1'],\n",
    "    name='Round',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnbbv6cyidRH"
   },
   "source": [
    "The names of the inputs and outputs of the nodes give already an idea of the structure of the resulting graph. In order to integrate the nodes into a graph environment, the inputs and outputs of the graph have to be specified first. In ONNX all data edges are processed as tensors. So with onnx helper function tensors value infos are created for the input and output tensors of the graph. Float from ONNX is used as data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fhyVRT7iU_2"
   },
   "outputs": [],
   "source": [
    "in1 = onnx.helper.make_tensor_value_info(\"in1\", onnx.TensorProto.FLOAT, [4, 4])\n",
    "in2 = onnx.helper.make_tensor_value_info(\"in2\", onnx.TensorProto.FLOAT, [4, 4])\n",
    "in3 = onnx.helper.make_tensor_value_info(\"in3\", onnx.TensorProto.FLOAT, [4, 4])\n",
    "out1 = onnx.helper.make_tensor_value_info(\"out1\", onnx.TensorProto.FLOAT, [4, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-cZesn4iucO"
   },
   "source": [
    "Now the graph can be built. First all nodes are passed. Here it is to be noted that it requires a certain sequence. The nodes must be instantiated in their dependencies to each other. This means Add2 must not be listed before Add1, because Add2 depends on the result of Add1. A name is then assigned to the graph. This is followed by the inputs and outputs.\n",
    "\n",
    "`value_info` of the graph contains the remaining tensors within the graph. When creating the nodes we have already defined names for the inner data edges and now these are assigned tensors of the datatype float and a certain shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0UgraOxitI_"
   },
   "outputs": [],
   "source": [
    "graph = onnx.helper.make_graph(\n",
    "      nodes=[\n",
    "          Add1_node,\n",
    "          Add2_node,\n",
    "          Abs_node,\n",
    "          Add3_node,\n",
    "          Round_node,\n",
    "      ],\n",
    "      name=\"simple_graph\",\n",
    "      inputs=[in1, in2, in3],\n",
    "      outputs=[out1],\n",
    "      value_info=[\n",
    "          onnx.helper.make_tensor_value_info(\"sum1\", onnx.TensorProto.FLOAT, [4, 4]),\n",
    "          onnx.helper.make_tensor_value_info(\"sum2\", onnx.TensorProto.FLOAT, [4, 4]),\n",
    "          onnx.helper.make_tensor_value_info(\"abs1\", onnx.TensorProto.FLOAT, [4, 4]),\n",
    "          onnx.helper.make_tensor_value_info(\"sum3\", onnx.TensorProto.FLOAT, [4, 4]),\n",
    "      ],\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kclQn-2oitwV"
   },
   "source": [
    "**Important**: In our example, the shape of the tensors does not change during the calculation. This is not always the case. So you have to make sure that you specify the shape correctly.\n",
    "\n",
    "Now a model can be created from the graph and saved using the `.save` function. The model is saved in .onnx format and can be reloaded with `onnx.load()`. This also means that you can easily share your own model in .onnx format with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUypGjBQigG2"
   },
   "outputs": [],
   "source": [
    "onnx_model = qonnx_make_model(graph, producer_name=\"simple-model\")\n",
    "onnx.save(onnx_model, 'simple_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IizbMJ_ejktP"
   },
   "source": [
    "To visualize the created model, [Netron](https://github.com/lutzroeder/netron) can be used. Netron is a visualizer for neural network, deep learning and machine learning models. We provide a utility function for visualization with Netron, which we import and use in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3FcV3DPyi9Aa",
    "outputId": "2f4d69ac-2296-4a12-c769-8c545f9b87e5"
   },
   "outputs": [],
   "source": [
    "%pip install netron\n",
    "import netron\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "\n",
    "def showInNetron(model_filename: str, localhost_url: str = None, port: int = None):\n",
    "    \"\"\"Shows a ONNX model file in the Jupyter Notebook using Netron.\n",
    "\n",
    "    :param model_filename: The path to the ONNX model file.\n",
    "    :type model_filename: str\n",
    "\n",
    "    :param localhost_url: The IP address used by the Jupyter IFrame to show the model.\n",
    "     Defaults to localhost.\n",
    "    :type localhost_url: str, optional\n",
    "\n",
    "    :param port: The port number used by Netron and the Jupyter IFrame to show\n",
    "     the ONNX model.  Defaults to 8081.\n",
    "    :type port: int, optional\n",
    "\n",
    "    :return: The IFrame displaying the ONNX model.\n",
    "    :rtype: IPython.lib.display.IFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        port = port or int(os.getenv(\"NETRON_PORT\", default=\"8081\"))\n",
    "    except ValueError:\n",
    "        port = 8081\n",
    "    localhost_url = localhost_url or os.getenv(\"LOCALHOST_URL\", default=\"localhost\")\n",
    "    netron.start(model_filename, address=(\"0.0.0.0\", port), browse=False)\n",
    "    return IFrame(src=f\"http://{localhost_url}:{port}/\", width=\"100%\", height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "id": "N_qDB7f0jmy0",
    "outputId": "dd4ae3a5-1abb-41a0-f528-392798646666"
   },
   "outputs": [],
   "source": [
    "showInNetron('simple_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZvGUoVvjtaG"
   },
   "source": [
    "Netron also allows you to interactively explore the model. If you click on a node, the node attributes will be displayed. \n",
    "\n",
    "In order to test the resulting model, a function is first written in Python that calculates the expected output. Because numpy arrays are to be used, numpy is imported first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "import numpy as np\n",
    "\n",
    "def expected_output(in1, in2, in3):\n",
    "    sum1 = np.add(in1, in2)\n",
    "    sum2 = np.add(sum1, in3)\n",
    "    abs1 = np.absolute(sum2)\n",
    "    sum3 = np.add(abs1, abs1)\n",
    "    return np.round(sum3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the values for the three inputs are calculated. Random numbers are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in1_values = np.asarray(np.random.uniform(low=-5, high=5, size=(4,4)), dtype=np.float32)\n",
    "in2_values = np.asarray(np.random.uniform(low=-5, high=5, size=(4,4)), dtype=np.float32)\n",
    "in3_values = np.asarray(np.random.uniform(low=-5, high=5, size=(4,4)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily pass the values to the function we just wrote to calculate the expected result. For the created model the inputs must be summarized in a dictionary, which is then passed on to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {}\n",
    "input_dict[\"in1\"] = in1_values\n",
    "input_dict[\"in2\"] = in2_values\n",
    "input_dict[\"in3\"] = in3_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the model and calculate the output, [onnxruntime](https://github.com/microsoft/onnxruntime) can be used. ONNX Runtime is a performance-focused complete scoring engine for ONNX models from Microsoft. The `.InferenceSession` function is used to create a session of the model and `.run` is used to execute the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install onnxruntime\n",
    "import onnxruntime as rt\n",
    "\n",
    "sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "output = sess.run(None, input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input values are also transferred to the reference function. Now the output of the execution of the model can be compared with that of the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_output= expected_output(in1_values, in2_values, in3_values)\n",
    "print(\"The output of the ONNX model is: \\n{}\".format(output[0]))\n",
    "print(\"\\nThe output of the reference function is: \\n{}\".format(ref_output))\n",
    "\n",
    "if (output[0] == ref_output).all():\n",
    "    print(\"\\nThe results are the same!\")\n",
    "else:\n",
    "    raise Exception(\"Something went wrong, the output of the model doesn't match the expected output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have verified that the model works as we expected it to, we can continue working with the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. How to manipulate an ONNX model\n",
    "\n",
    "In the model there are two successive adder nodes. An adder node in ONNX can only add two inputs, but there is also the [**sum**](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sum) node, which can process more than two inputs. So it would be a reasonable change of the graph to combine the two successive adder nodes to one sum node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we assume that we do not know the appearance of the model, so we first try to identify whether there are two consecutive adders in the graph and then convert them into a sum node. \n",
    "\n",
    "Here we make use of QONNX compiler infrastructure. The QONNX repo provides a thin wrapper around the model which provides several additional helper functions to manipulate the graph. The code can be found [here](https://github.com/fastmachinelearning/qonnx/blob/main/src/qonnx/core/modelwrapper.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qonnx\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "qonnx_model = ModelWrapper(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the previous section, it is important that the nodes are listed in the correct order. If a new node has to be inserted or an old node has to be replaced, it is important to do that in the appropriate position. The following function serves this purpose. It returns a dictionary, which contains the node name as key and the respective node index as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_id(model):\n",
    "    node_index = {}\n",
    "    node_ind = 0\n",
    "    for node in model.graph.node:\n",
    "        node_index[node.name] = node_ind\n",
    "        node_ind += 1\n",
    "    return node_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function scans the list of nodes and stores a run index (`node_ind`) as node index in the dictionary for every node name.\n",
    "\n",
    "Another helper function is being implemented that searches for adder nodes in the graph and returns the found nodes. This is needed to determine if and which adder nodes are in the given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_adder_nodes(model):\n",
    "    add_nodes = []\n",
    "    for node in model.graph.node:\n",
    "        if node.op_type == \"Add\":\n",
    "            add_nodes.append(node)\n",
    "    return add_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function iterates over all nodes of the model and if the operation type is `\"Add\"` the node will be stored in `add_nodes`. At the end `add_nodes` is returned.\n",
    "\n",
    "If we apply this to our model, three nodes should be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_nodes = identify_adder_nodes(qonnx_model)\n",
    "for node in add_nodes:\n",
    "    print(\"Found adder node: {}\".format(node.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among other helper functions, `ModelWrapper` offers two functions that can help to determine the preceding and succeeding node of a node. However, these functions are not getting a node as input, but can determine the consumer or producer of a tensor. We write two functions that uses these helper functions to determine the previous and the next node of a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_predecessor(model, node):\n",
    "    predecessors = []\n",
    "    for i in range(len(node.input)):\n",
    "        producer = model.find_producer(node.input[i])\n",
    "        predecessors.append(producer)\n",
    "    return predecessors\n",
    "        \n",
    "\n",
    "def find_successor(model, node):\n",
    "    successors = []\n",
    "    for i in range(len(node.output)):\n",
    "        consumer = model.find_consumer(node.output[i])\n",
    "        successors.append(consumer)\n",
    "    return successors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function uses `find_producer` from `ModelWrapper` to create a list of the producers of the inputs of the given node. So the returned list is indirectly filled with the predecessors of the node. The second function works in a similar way, `find_consumer` from `ModelWrapper` is used to find the consumers of the output tensors of the node and so a list with the successors can be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adder_pair(model, node):\n",
    "    adder_pairs = []\n",
    "    node_pair = []\n",
    "    successor_list = find_successor(model, node)\n",
    "    \n",
    "    for successor in successor_list:\n",
    "        if successor.op_type == \"Add\":\n",
    "            node_pair.append(node)\n",
    "            node_pair.append(successor)\n",
    "            adder_pairs.append((node_pair))\n",
    "            node_pair = []\n",
    "    return adder_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function gets a node and the model as input. Two empty lists are created to be filled with a list of adder node pairs that can be returned as result of the function. Then the function `find_successor` is used to return all of the successors of the node. If one of the successors is an adder node, the node is saved in `node_pair` together with the successive adder node and put in the list `adder_pairs`. Then the temporary list is cleaned and can be filled with the next adder node pair. Since it is theoretically possible for an adder node to have more than one subsequent adder node, a list of lists is created. This list of the node with all its successive adder nodes is returned.\n",
    "\n",
    "So now we can find out which adder node has an adder node as successor. Since the model is known, one adder pair (Add1+Add2) should be found when applying the function to the previously determined adder node list (`add_nodes`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in add_nodes:\n",
    "    add_pairs = adder_pair(qonnx_model, node)\n",
    "    if len(add_pairs) != 0:\n",
    "        for i in range(len(add_pairs)):\n",
    "            substitute_pair = add_pairs[i]\n",
    "            print(\"Found following pair that could be replaced by a sum node:\")\n",
    "            for node_pair in add_pairs:\n",
    "                for node in node_pair:\n",
    "                    print(node.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the pair to be replaced has been identified (`substitute_pair`), a sum node can be instantiated and inserted into the graph at the correct position. \n",
    "\n",
    "First of all, the inputs must be determined. For this the adder nodes inputs are used minus the input, which corresponds to the output of the other adder node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "for i in range(len(substitute_pair)):\n",
    "    if i == 0:\n",
    "        for j in range(len(substitute_pair[i].input)):\n",
    "            if substitute_pair[i].input[j] != substitute_pair[i+1].output[0]:\n",
    "                input_list.append(substitute_pair[i].input[j])\n",
    "    else:\n",
    "        for j in range(len(substitute_pair[i].input)):\n",
    "            if substitute_pair[i].input[j] != substitute_pair[i-1].output[0]:\n",
    "                input_list.append(substitute_pair[i].input[j])\n",
    "print(\"The new node gets the following inputs: \\n{}\".format(input_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the sum node matches the output of the second adder node and can therefore be taken over directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_output = substitute_pair[1].output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary node can be created with this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_node = onnx.helper.make_node(\n",
    "    'Sum',\n",
    "    inputs=input_list,\n",
    "    outputs=[sum_output],\n",
    "    name=\"Sum\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The node can now be inserted into the graph and the old nodes are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids = get_node_id(qonnx_model)\n",
    "node_ind = node_ids[substitute_pair[0].name]\n",
    "graph.node.insert(node_ind, Sum_node)\n",
    "\n",
    "for node in substitute_pair:\n",
    "    graph.node.remove(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To insert the node in the right place, the index of the first node of the substitute_pair is used as node index for the sum node and embedded into the graph using `.insert`. Then the two elements in `substitute_pair` are deleted using `.remove`. `.insert` and `.remove` are functions provided by ONNX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new graph is saved as ONNX model and can be visualized with Netron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model1 = qonnx.util.basic.qonnx_make_model(graph, producer_name=\"simple-model1\")\n",
    "onnx.save(onnx_model1, 'simple_model1.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron('simple_model1.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the visualization it can already be seen that the insertion was successful, but it is still to be checked whether the result remains the same. Therefore the result of the reference function written in the previous section is used and the new model with the input values is simulated. At this point onnxruntime can be used again. The simulation is analogous to the one of the first model in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(onnx_model1.SerializeToString())\n",
    "output = sess.run(None, input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The output of the manipulated ONNX model is: \\n{}\".format(output[0]))\n",
    "print(\"\\nThe output of the reference function is: \\n{}\".format(ref_output))\n",
    "\n",
    "if (output[0] == ref_output).all():\n",
    "    print(\"\\nThe results are the same!\")\n",
    "else:\n",
    "    raise Exception(\"Something went wrong, the output of the model doesn't match the expected output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. QONNX - Analysis Passes\n",
    "\n",
    "This part is about the analysis passes of QONNX.\n",
    "\n",
    "We'll use the following utility functions to print the source code for function calls (`showSrc()`) and to visualize a network using netron (`showInNetron()`) in the Jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import netron\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "import urllib.request\n",
    "\n",
    "def showSrc(what):\n",
    "    print(\"\".join(inspect.getsourcelines(what)[0]))\n",
    "\n",
    "def download_model_from_zoo(qonnx_url, dl_file):\n",
    "    urllib.request.urlretrieve(qonnx_url, dl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Example - Quantity analysis of operation types\n",
    "As an example, an analysis is designed that returns the number of nodes of the same operation types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the model is shown to illustrate the analysis. For this Netron is used. Netron is a visualizer for neural network, deep learning and machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_model_from_zoo(\"https://github.com/fastmachinelearning/QONNX_model_zoo/raw/main/models/MNIST/Brevitas_FINN_TFC/TFC/TFC_2W2A.onnx\", \"TFC_2W2A.onnx\")\n",
    "showInNetron(\"TFC_2W2A.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load the model with the `ModelWrapper` to work with it in QONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "model = ModelWrapper('TFC_2W2A.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with what we did above and see if it also works on a more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_nodes = identify_adder_nodes(model)\n",
    "for node in add_nodes:\n",
    "    print(\"Found adder node: {}\".format(node.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to count all nodes that have the same operation type. The result should contain the operation types and the corresponding number of nodes that occur in the model. In the beginning an empty dictionary is created which is filled by the function and returned as result to the user at the end of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_node_types(model):\n",
    "    count_dict = {}\n",
    "    for node in model.graph.node:\n",
    "        if node.op_type in count_dict:\n",
    "            count_dict[node.op_type] +=1\n",
    "        else:\n",
    "            count_dict[node.op_type] = 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function takes the model as input and iterates over the nodes. Then it is checked whether there is already an entry for the operation type in the dictionary. If this is not the case, an entry is created and set to `1`. If there is already an entry, it is incremented. If all nodes in the model have been iterated, the filled dictionary is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis function of ModelWrapper is used to perform the analysis just designed. It is shown below and takes the function as input and performs it by passing the model to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showSrc(ModelWrapper.analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result can now simply be determined by calling the `.analysis` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.analysis(count_unique_node_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Calculate inference cost for QONNX model\n",
    "\n",
    "QONNX has a command line tool to get the inference cost (qonnx-inference-cost). \n",
    "\n",
    "But we can also compute it in a python program. For this we will use the CNV_2W2A model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_model_from_zoo(\"https://github.com/fastmachinelearning/qonnx_model_zoo/blob/main/models/CIFAR10/Brevitas_FINN_CNV/CNV_2W2A.onnx\", \"CNV_2W2A.onnx\")\n",
    "showInNetron(\"TFC_2W2A.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.util.inference_cost import inference_cost\n",
    "model = ModelWrapper('TFC_2W2A.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_cost(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. QONNX - Transformation Passes\n",
    "\n",
    "In this part the idea behind transformation passes in QONNX will be explained and with the help of an example the procedure of a transformation will be shown.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .transform() from ModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "showSrc(ModelWrapper.transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the function is called, the model, the name of the transformation and, if required, the flag make_deepcopy are passed. It is also possible not to make a copy of the model. In this case `make_deepcopy` must be set to False. Then the branch `if make_deepcopy:` would not be taken and no copy of the model would be made. \n",
    "\n",
    "The unchanged model is first passed to the variable `transformed_model` to pass this variable on to the transformation later. \n",
    "\n",
    "`model_was_changed` indicates whether the transformation needs to be applied more then once. Because it needs to be applied at least one time `model_was_changed` is first set to True and then depending on the return values of the transformation function the transformation can be applied more then once. \n",
    "\n",
    "**Important**: Due to the structure of this function, `model_was_changed` must be set to False at some point. Otherwise the loop is infinite.\n",
    "    \n",
    "\n",
    "Each new transformation must correspond to the scheme of the base class and contain at least the function `apply(model)`, which returns the changed model and a bool value for `model_was_changed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.base import Transformation\n",
    "showSrc(Transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base class is abstract class (`import ABC`) with only one abstract method (`apply()`) which gets the model as input. To show what a transformation should look like, the following example is taken from a general-purpose QONNX transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - ConvertSubToAdd\n",
    "The transformation replaces all subtraction nodes in a model with addition nodes with appropriate sign. For that an onnx model is loaded which contains one subtraction node. \n",
    "    \n",
    "Netron is used to visualize the result before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('TFC_2W2A.onnx')\n",
    "onnx_model = ModelWrapper(onnx_model)\n",
    "showInNetron(\"TFC_2W2A.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.base import Transformation\n",
    "\n",
    "class ConvertSubToAdd(Transformation):\n",
    "    def apply(self, model):\n",
    "        graph = model.graph\n",
    "        for n in graph.node:\n",
    "            if n.op_type == \"Sub\":\n",
    "                A = model.get_initializer(n.input[1])\n",
    "                if A is not None:\n",
    "                    n.op_type = \"Add\"\n",
    "                    model.set_initializer(n.input[1], -A)\n",
    "        return (model, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the transformation class must be imported. Then a class can be created for the new transformation, which is derived from the base class. In this case the transformation has only the `apply()` function. \n",
    "\n",
    "All nodes are checked by first extracting the graph from the model and then iterating over the node list. With the help of .op_type the operation type of the node can be checked, if the node is a subtraction node the condition `if n.op_type == \"Sub\"` is true. It may be that the subtraction input of the node has no value, this is checked with `model.get_initializer(n.input[1])`. \n",
    "    \n",
    "    \n",
    "**Important:** As with ONNX, QONNX always assumes a certain order of inputs, this is especially important if you want to create additional custom operation nodes.\n",
    "\n",
    "When the input is initialized, the operation type of the node is converted to `\"Add\"`, this can simply be done by using the equal sign. Then the sign of the initial value must be changed. For this the ModelWrapper function `.set_initializer` can be used.\n",
    "\n",
    "At the end the changed model is returned and `model_was_changed` is set to False, because the transformation has to be executed only once.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_transformed = onnx_model.transform(ConvertSubToAdd())\n",
    "onnx_model_transformed.save('/tmp/LFCW1A1_changed.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron('/tmp/LFCW1A1_changed.onnx')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
